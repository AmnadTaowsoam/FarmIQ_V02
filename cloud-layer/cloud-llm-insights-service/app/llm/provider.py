from __future__ import annotations

import asyncio
import json
import os
import time
from dataclasses import dataclass
from typing import Any, Protocol

from app.schemas import AnalyzeRequest
from app.prompts import get_template, build_kpis_section, build_anomalies_section, PromptVersion
from app.llm.circuit_breaker import CircuitBreaker, CircuitBreakerConfig, CircuitBreakerError
from app.llm.health_monitor import get_health_monitor, HealthStatus


@dataclass
class ProviderRunMeta:
    token_in: int | None = None
    token_out: int | None = None
    provider_latency_ms: int | None = None


class LlmProvider(Protocol):
    async def analyze(self, request: AnalyzeRequest) -> tuple[dict[str, Any], ProviderRunMeta]: ...


class MockProvider:
    def __init__(self, *, provider_name: str, model_name: str, prompt_version: str):
        self._provider_name = provider_name
        self._model_name = model_name
        self._prompt_version = prompt_version

    async def analyze(self, request: AnalyzeRequest) -> tuple[dict[str, Any], ProviderRunMeta]:
        payload = request.model_dump(mode="json")
        token_in = max(1, len(json.dumps(payload)) // 4)

        fcr = None
        for kpi in request.features.kpis:
            if kpi.code.upper() == "FCR":
                fcr = kpi
                break

        anomaly_count = len(request.features.anomalies)
        summary_parts: list[str] = []
        if fcr:
            summary_parts.append(f"FCR is {fcr.value:.2f}.")
            if fcr.delta24h is not None:
                delta = fcr.delta24h
                direction = "increased" if delta > 0 else "decreased"
                summary_parts.append(f"FCR {direction} by {abs(delta):.2f} vs prior 24h.")
        if anomaly_count:
            summary_parts.append(f"{anomaly_count} anomaly(ies) detected in selected window.")

        summary = " ".join(summary_parts) if summary_parts else "No significant deviations detected in the selected window."
        confidence = 0.68 if anomaly_count or fcr else 0.55

        should_notify = bool(anomaly_count) or (request.mode in ("anomaly_explain", "action_recommendation"))
        severity: str = "info"
        if anomaly_count:
            sev_set = {a.severity for a in request.features.anomalies}
            severity = "critical" if "critical" in sev_set else "warning"

        insight: dict[str, Any] = {
            "summary": summary,
            "keyFindings": [
                {
                    "title": "Deterministic mock insight",
                    "detail": "This insight is generated by mock provider for MVP and testing.",
                    "impact": "low",
                    "references": [],
                }
            ],
            "likelyCauses": [],
            "recommendedActions": [],
            "confidence": confidence,
            "references": [],
            "modelMeta": {
                "provider": self._provider_name,
                "model": self._model_name,
                "promptVersion": self._prompt_version,
            },
            "notificationHint": {
                "shouldNotify": should_notify,
                "severity": severity,
                "title": "New insight available",
                "message": "An insight was generated for your selected barn and time window.",
            },
        }

        token_out = max(1, len(json.dumps(insight)) // 4)
        return insight, ProviderRunMeta(token_in=token_in, token_out=token_out)


class OpenAIProvider:
    """Real OpenAI LLM provider with circuit breaker and health monitoring."""

    def __init__(self, *, model_name: str, prompt_version: str, api_key: str | None = None):
        try:
            from openai import AsyncOpenAI
        except ImportError:
            raise RuntimeError("openai package not installed. Install with: pip install openai")

        self._client = AsyncOpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))
        self._model_name = model_name
        self._prompt_version = prompt_version
        self._provider_name = "openai"
        
        # Initialize circuit breaker
        self._circuit_breaker = CircuitBreaker(
            config=CircuitBreakerConfig(
                failure_threshold=5,
                success_threshold=2,
                timeout_seconds=60.0,
                call_timeout_seconds=30.0,
            ),
            name=f"openai-{model_name}"
        )
        
        # Register with health monitor
        health_monitor = get_health_monitor()
        health_monitor.register_provider(
            provider_name="openai",
            model_name=model_name,
            health_checker=self._health_check,
        )

    async def _health_check(self) -> bool:
        """Health check for OpenAI provider."""
        try:
            from openai import AsyncOpenAI
            client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            # Simple health check - list models
            await client.models.list()
            return True
        except Exception:
            return False

    async def analyze(self, request: AnalyzeRequest) -> tuple[dict[str, Any], ProviderRunMeta]:
        """Analyze using OpenAI API."""
        start_time = time.perf_counter()

        # Build prompt from request using template system
        prompt = self._build_prompt(request)

        try:
            response = await self._client.chat.completions.create(
                model=self._model_name,
                messages=[
                    {"role": "system", "content": "You are an agricultural AI assistant specializing in livestock management and farm analytics."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )

            latency_ms = int((time.perf_counter() - start_time) * 1000)

            content = response.choices[0].message.content or ""
            token_in = response.usage.prompt_tokens
            token_out = response.usage.completion_tokens

            # Parse response into insight format
            insight = self._parse_response(content)

            # Add model metadata
            insight["modelMeta"] = {
                "provider": self._provider_name,
                "model": self._model_name,
                "promptVersion": self._prompt_version,
            }

            return insight, ProviderRunMeta(
                token_in=token_in,
                token_out=token_out,
                provider_latency_ms=latency_ms
            )
        except Exception as e:
            raise RuntimeError(f"OpenAI API error: {e}") from e

    async def analyze_with_circuit_breaker(self, request: AnalyzeRequest) -> tuple[dict[str, Any], ProviderRunMeta]:
        """Analyze using circuit breaker protection."""
        return await self._circuit_breaker.call(self.analyze, request)

    def _build_prompt(self, request: AnalyzeRequest) -> str:
        """Build prompt from request data using template system."""
        # Determine which template to use based on mode
        template_name = "telemetry_analysis"
        if request.mode == "anomaly_explain":
            template_name = "anomaly_explanation"
        elif request.mode == "action_recommendation":
            template_name = "action_recommendation"

        # Get template based on prompt version
        try:
            version = PromptVersion(self._prompt_version)
        except ValueError:
            version = PromptVersion.V1_1  # Default to latest

        template = get_template(template_name, version)

        # Build prompt sections
        kpis_section = build_kpis_section(request.features.kpis) if request.features.kpis else "No KPIs available."
        anomalies_section = build_anomalies_section(request.features.anomalies) if request.features.anomalies else "No anomalies detected."
        time_window = f"{request.window.startTime} to {request.window.endTime}"

        # Render template
        return template.render(
            kpis_section=kpis_section,
            anomalies_section=anomalies_section,
            mode=request.mode,
            time_window=time_window,
            historical_context="Historical data available for comparison.",
        )

    def _parse_response(self, content: str) -> dict[str, Any]:
        """Parse OpenAI response into insight format."""
        # For MVP, return a basic structure
        # In production, this would parse structured JSON from LLM
        return {
            "summary": content[:500] + "..." if len(content) > 500 else content,
            "keyFindings": [
                {
                    "title": "AI-Generated Insight",
                    "detail": content,
                    "impact": "medium",
                    "references": [],
                }
            ],
            "likelyCauses": [],
            "recommendedActions": [],
            "confidence": 0.7,
            "references": [],
            "notificationHint": {
                "shouldNotify": True,
                "severity": "info",
                "title": "New AI insight available",
                "message": "An AI-generated insight is ready for review.",
            },
        }


class AnthropicProvider:
    """Real Anthropic (Claude) LLM provider with circuit breaker and health monitoring."""

    def __init__(self, *, model_name: str, prompt_version: str, api_key: str | None = None):
        try:
            from anthropic import AsyncAnthropic
        except ImportError:
            raise RuntimeError("anthropic package not installed. Install with: pip install anthropic")

        self._client = AsyncAnthropic(api_key=api_key or os.getenv("ANTHROPIC_API_KEY"))
        self._model_name = model_name
        self._prompt_version = prompt_version
        self._provider_name = "anthropic"
        
        # Initialize circuit breaker
        self._circuit_breaker = CircuitBreaker(
            config=CircuitBreakerConfig(
                failure_threshold=5,
                success_threshold=2,
                timeout_seconds=60.0,
                call_timeout_seconds=30.0,
            ),
            name=f"anthropic-{model_name}"
        )
        
        # Register with health monitor
        health_monitor = get_health_monitor()
        health_monitor.register_provider(
            provider_name="anthropic",
            model_name=model_name,
            health_checker=self._health_check,
        )

    async def _health_check(self) -> bool:
        """Health check for Anthropic provider."""
        try:
            from anthropic import AsyncAnthropic
            client = AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
            # Simple health check - list models
            await client.models.list()
            return True
        except Exception:
            return False

    async def analyze(self, request: AnalyzeRequest) -> tuple[dict[str, Any], ProviderRunMeta]:
        """Analyze using Anthropic API."""
        start_time = time.perf_counter()

        # Build prompt from request using template system
        prompt = self._build_prompt(request)

        try:
            response = await self._client.messages.create(
                model=self._model_name,
                max_tokens=1000,
                messages=[{"role": "user", "content": prompt}],
                system="You are an agricultural AI assistant specializing in livestock management and farm analytics."
            )

            latency_ms = int((time.perf_counter() - start_time) * 1000)

            content = response.content[0].text if response.content else ""
            token_in = response.usage.input_tokens
            token_out = response.usage.output_tokens

            # Parse response into insight format
            insight = self._parse_response(content)

            # Add model metadata
            insight["modelMeta"] = {
                "provider": self._provider_name,
                "model": self._model_name,
                "promptVersion": self._prompt_version,
            }

            return insight, ProviderRunMeta(
                token_in=token_in,
                token_out=token_out,
                provider_latency_ms=latency_ms
            )
        except Exception as e:
            raise RuntimeError(f"Anthropic API error: {e}") from e

    async def analyze_with_circuit_breaker(self, request: AnalyzeRequest) -> tuple[dict[str, Any], ProviderRunMeta]:
        """Analyze using circuit breaker protection."""
        return await self._circuit_breaker.call(self.analyze, request)

    def _build_prompt(self, request: AnalyzeRequest) -> str:
        """Build prompt from request data using template system."""
        # Determine which template to use based on mode
        template_name = "telemetry_analysis"
        if request.mode == "anomaly_explain":
            template_name = "anomaly_explanation"
        elif request.mode == "action_recommendation":
            template_name = "action_recommendation"

        # Get template based on prompt version
        try:
            version = PromptVersion(self._prompt_version)
        except ValueError:
            version = PromptVersion.V1_1  # Default to latest

        template = get_template(template_name, version)

        # Build prompt sections
        kpis_section = build_kpis_section(request.features.kpis) if request.features.kpis else "No KPIs available."
        anomalies_section = build_anomalies_section(request.features.anomalies) if request.features.anomalies else "No anomalies detected."
        time_window = f"{request.window.startTime} to {request.window.endTime}"

        # Render template
        return template.render(
            kpis_section=kpis_section,
            anomalies_section=anomalies_section,
            mode=request.mode,
            time_window=time_window,
            historical_context="Historical data available for comparison.",
        )

    def _parse_response(self, content: str) -> dict[str, Any]:
        """Parse Anthropic response into insight format."""
        # Same as OpenAI for now
        return {
            "summary": content[:500] + "..." if len(content) > 500 else content,
            "keyFindings": [
                {
                    "title": "AI-Generated Insight",
                    "detail": content,
                    "impact": "medium",
                    "references": [],
                }
            ],
            "likelyCauses": [],
            "recommendedActions": [],
            "confidence": 0.7,
            "references": [],
            "notificationHint": {
                "shouldNotify": True,
                "severity": "info",
                "title": "New AI insight available",
                "message": "An AI-generated insight is ready for review.",
            },
        }


async def call_with_timeout(
    provider: LlmProvider, *, request: AnalyzeRequest, timeout_s: float
) -> tuple[dict[str, Any], ProviderRunMeta]:
    """Call provider with timeout and exponential backoff retry."""
    max_retries = 3
    base_delay = 1.0

    for attempt in range(max_retries):
        try:
            return await asyncio.wait_for(provider.analyze(request), timeout=timeout_s)
        except asyncio.TimeoutError:
            if attempt == max_retries - 1:
                raise
            await asyncio.sleep(base_delay * (2 ** attempt))
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            await asyncio.sleep(base_delay * (2 ** attempt))

    # Should never reach here
    raise RuntimeError("Max retries exceeded")


class ProviderManager:
    """Manages multiple LLM providers with fallback and health-based routing."""

    def __init__(self, providers: list[LlmProvider], fallback_enabled: bool = True):
        self._providers = providers
        self._fallback_enabled = fallback_enabled
        self._health_monitor = get_health_monitor()

    async def analyze(self, request: AnalyzeRequest, timeout_s: float = 30.0) -> tuple[dict[str, Any], ProviderRunMeta]:
        """Analyze with provider fallback."""
        available_providers = self._health_monitor.get_available_providers()
        
        # Try available providers first
        for provider in self._providers:
            provider_name = getattr(provider, "_provider_name", "unknown")
            model_name = getattr(provider, "_model_name", "unknown")
            
            # Check if provider is available
            if (provider_name, model_name) not in available_providers:
                logger.warning(f"Provider {provider_name}:{model_name} is not available, skipping")
                continue
            
            try:
                # Use circuit breaker if available
                if hasattr(provider, "analyze_with_circuit_breaker"):
                    return await provider.analyze_with_circuit_breaker(request)
                else:
                    return await call_with_timeout(provider, request=request, timeout_s=timeout_s)
            except CircuitBreakerError as e:
                logger.warning(f"Circuit breaker open for {provider_name}:{model_name}: {e}")
                if not self._fallback_enabled:
                    raise
                continue
            except Exception as e:
                logger.error(f"Provider {provider_name}:{model_name} failed: {e}")
                if not self._fallback_enabled:
                    raise
                continue
        
        # All providers failed
        raise RuntimeError("All LLM providers failed or are unavailable")

    def get_provider_status(self) -> dict[str, Any]:
        """Get status of all providers."""
        return self._health_monitor.get_all_status()
